{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team:\n",
    "    \n",
    "Sanket Talaviya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We have used fastai and transformers to solve this problem.\n",
    "\n",
    "The fastai library simplifies training fast and accurate neural nets using modern best practices. \n",
    "The library is based on research into deep learning best practices undertaken at fast.ai, and includes \"out of the box\" support for vision, text, tabular, and collab (collaborative filtering) models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training methodology:\n",
    "\n",
    "Now we can finally use all the fastai build-in features to train our model. we will use **Slanted Triangular Learning Rates**, **Discriminate Learning Rate** and **gradually unfreeze the model**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notable aspects\n",
    "\n",
    "Using pretrained RoBERTa model from transformer package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "1. https://docs.fast.ai/callbacks.one_cycle.html\n",
    "2. https://towardsdatascience.com/fastai-with-transformers-bert-roberta-xlnet-xlm-distilbert-4f41ee18ecb2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "    Please note Data isnt uploaded here. So you need to create data folder and put train.csv and test.csv files in that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q fastai\n",
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from pathlib import Path \n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import random \n",
    "\n",
    "# fastai\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "\n",
    "# transformers\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1900, 2) (211, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>No one cares about marketing slides - a techni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Are all three hosts providing storage/capacity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>would loved to had managed to get down to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Vending machine at work is out of Dasani water...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @VMwareEdu: Paul Maritz, CEO and President ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0  Negative  No one cares about marketing slides - a techni...\n",
       "1  Positive  Are all three hosts providing storage/capacity...\n",
       "2  Negative  would loved to had managed to get down to the ...\n",
       "3  Negative  Vending machine at work is out of Dasani water...\n",
       "4  Positive  RT @VMwareEdu: Paul Maritz, CEO and President ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv( './data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "print(train.shape,test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "seed = 42\n",
    "use_fp16 = False\n",
    "bs = 16\n",
    "\n",
    "model_type = 'roberta'\n",
    "pretrained_model_name = 'roberta-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, config_class = (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the available values for ``pretrained_model_name`` (shortcut names) corresponding to the ``model_type`` used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to set the seed for generating random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value) # Python\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can simply create a new class TransformersBaseTokenizer that inherits from BaseTokenizer and overwrite a new tokenizer function.\n",
    "\n",
    "class TransformersBaseTokenizer(BaseTokenizer):\n",
    "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
    "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
    "        self._pretrained_tokenizer = pretrained_tokenizer\n",
    "        self.max_seq_len = pretrained_tokenizer.max_len\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def __call__(self, *args, **kwargs): \n",
    "        return self\n",
    "\n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
    "        CLS = self._pretrained_tokenizer.cls_token\n",
    "        SEP = self._pretrained_tokenizer.sep_token\n",
    "        tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
    "        tokens = [CLS] + tokens + [SEP]\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
    "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
    "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## It is worth noting that we don't add padding in this part of the implementation. As we will see later, fastai manage it automatically during the creation of the DataBunch.\n",
    "## In fastai, NumericalizeProcessor object takes as vocab argument a Vocab object. From this analyse, there are two ways to adapt the fastai numericalizer:\n",
    "\n",
    "# 1)  retreive the list of tokens and create a Vocab object.\n",
    "# 2) Create a new class TransformersVocab that inherits from Vocab and overwrite numericalize and textify functions.\n",
    "\n",
    "## We will go ahead with #2 option.\n",
    "\n",
    "class TransformersVocab(Vocab):\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
    "        super(TransformersVocab, self).__init__(itos = [])\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
    "        \"Convert a list of tokens `t` to their ids.\"\n",
    "        return self.tokenizer.convert_tokens_to_ids(t)\n",
    "        #return self.tokenizer.encode(t)\n",
    "\n",
    "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
    "        \"Convert a list of `nums` to their tokens.\"\n",
    "        nums = np.array(nums).tolist()\n",
    "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)\n",
    "    \n",
    "    def __getstate__(self):\n",
    "        return {'itos':self.itos, 'tokenizer':self.tokenizer}\n",
    "\n",
    "    def __setstate__(self, state:dict):\n",
    "        self.itos = state['itos']\n",
    "        self.tokenizer = state['tokenizer']\n",
    "        self.stoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Notice we are passing the include_bos = False and include_eos = False options. \n",
    "## This is because fastai adds its own special tokens by default which interferes with the [CLS] and [SEP] tokens added by our custom tokenizer\n",
    "\n",
    "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
    "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
    "\n",
    "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n",
    "\n",
    "transformer_processor = [tokenize_processor, numericalize_processor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting up the Databunch\n",
    "## For the DataBunch creation, you have to pay attention to set the processor argument to our new custom processor ``transformer_processor`` and manage correctly the padding.\n",
    "## As mentioned in the HuggingFace documentation, BERT, RoBERTa, XLM and DistilBERT are models with absolute position embeddings, so it's usually advised to pad the inputs on the right rather than the left. \n",
    "\n",
    "pad_first = False\n",
    "pad_idx = transformer_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nice', 'Ġto', 'Ġsee', 'ĠVMware', 'Ġcompetition', 'Ġon', 'ĠMachine', 'ĠLearning']\n",
      "[41541, 7, 192, 32237, 1465, 15, 14969, 13807]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Nice',\n",
       " 'Ġto',\n",
       " 'Ġsee',\n",
       " 'ĠVMware',\n",
       " 'Ġcompetition',\n",
       " 'Ġon',\n",
       " 'ĠMachine',\n",
       " 'ĠLearning']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = transformer_tokenizer.tokenize('Nice to see VMware competition on Machine Learning')\n",
    "print(tokens)\n",
    "ids = transformer_tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(ids)\n",
    "transformer_tokenizer.convert_ids_to_tokens(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is multible ways to create a DataBunch, in our implementation, we use [the data block API](https://docs.fast.ai/data_block.html#The-data-block-API), which gives more flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    }
   ],
   "source": [
    "databunch = (TextList.from_df(train, cols='text', processor=transformer_processor)\n",
    "             .split_by_rand_pct(0.1,seed=seed)\n",
    "             .label_from_df(cols= 'label')\n",
    "             .add_test(test)\n",
    "             .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check batch and tokenizer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] token : <s>\n",
      "[SEP] token : </s>\n",
      "[PAD] token : <pad>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; ĠUpdate . ĠThere Ġreally Ġis Ġa Ġnetwork Ġissue . ĠI Ġhadn 't Ġcaught Ġit Ġbecause Ġit 's Ġasymm etrical . ĠNow Ġto Ġfigure Ġout Ġhow Ġto Ġfix Ġit . ĠIt Ġapplies Ġto Ġboth Ġports Ġon Ġthe ĠNIC Ġon Ġthe Ġserver . ĠDoing Ġsome Ġfinal Ġtroubles hooting Ġto Ġseparate Ġbetween ĠNIC Ġissue Ġand ĠSwitch Ġissue , Ġbut Ġman ... Ġthis Ġthing Ġhurt Ġme Ġfor Ġa Ġl oooo ong Ġwhile .</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; ĠWell ĠI Ġnoticed Ġa Ġconfiguration Ġerror ĠI Ġmade Ġwhen ĠI Ġoriginally Ġcame Ġup Ġwith Ġa Ġbudget Ġfor Ġthis Ġproject Ġ( too Ġmany Ġcapacity Ġs sd 's ). ĠWell Ġthey Ġapproved Ġit Ġat Ġthe Ġprice Ġit Ġwas Ġand Ġwhen ĠI Ġcorrected Ġmy Ġerror Ġand Ġswapped Ġthe ĠS 37 00 's Ġto Ġthe ĠP 37 00 Ġit Ġactually Ġended Ġup Ġcheaper , Ġso Ġwe Ġare Ġgoing Ġto Ġgo Ġwith Ġthat .</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; ĠThere Ġis Ġa Ġslightly Ġdifferent Ġmethod Ġfrom Ġsnapshots Ġyou Ġcan Ġuse Ġthat Ġmay Ġbe Ġthe Ġsolution Ġyou Ġare Ġlooking Ġfor . Ġ Ġ ĠCreate Ġyour Ġperfect Ġstarting ĠVM Ġthen Ġshut Ġit Ġdown Ġand Ġmake Ġthe Ġdisk Ġnon - pers istent . ĠDownload Ġthe Ġv mx Ġfile Ġand Ġuse Ġit Ġas Ġa Ġtemplate Ġto Ġmake Ġother Ġcl oned ĠV Ms . Ġ ĠYou Ġcan Ġupload Ġas Ġmany ĠV Ms Ġas</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; ĠAlright , Ġso Ġthis Ġis Ġgoing Ġto Ġbe Ġa Ġlittle Ġfunky Ġhere , Ġand Ġthere Ġis Ġa Ġvery Ġgood Ġchance Ġof Ġfucking Ġeverything Ġup ... Ġ ĠIf Ġyou Ġhave Ġany Ġspace Ġavailable , Ġuse Ġsomething Ġlike Ġg part d Ġand Ġcreate Ġtwo Ġpartitions . Ġ ĠMake Ġone Ġa Ġfew Ġgigs Ġin Ġsize Ġand Ġgive Ġthe Ġother Ġpartition Ġthe Ġrest Ġof Ġthe Ġspace . Ġ ĠThen Ġinstall ĠES Xi Ġon</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; ĠSo oo ĠJust Ġa Ġheads Ġup Ġ, ĠI Ġpush ĠVideo Ġediting Ġwork st ations Ġfrom ĠNYC Ġto ĠCal cut ta ĠIndia Ġand ĠMo Bay ĠJamaica Ġ. Ġ Ġ Ġ ĠPC O IP ĠIs Ġhow ĠI Ġdo Ġit Ġ. Ġ Ġ ĠI Ġhad Ġto Ġcustomize Ġthe ĠPC O IP Ġ( band width Ġfloor , Ġ Ġframe Ġrate , Ġau ido Ġquality .. ) Ġsettings Ġfor Ġeverything , Ġ Ġ ĠI</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('[CLS] token :', transformer_tokenizer.cls_token)\n",
    "print('[SEP] token :', transformer_tokenizer.sep_token)\n",
    "print('[PAD] token :', transformer_tokenizer.pad_token)\n",
    "databunch.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check batch and numericalizer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] id : 0\n",
      "[SEP] id : 2\n",
      "[PAD] id : 1\n",
      "Batch shape :  torch.Size([16, 512])\n",
      "tensor([[    0,   598, 17678,  ..., 10393,  2577,     2],\n",
      "        [    0,   345,    16,  ...,     1,     1,     1],\n",
      "        [    0, 41881,     6,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0,    38,    33,  ...,     1,     1,     1],\n",
      "        [    0,   440,   464,  ...,     1,     1,     1],\n",
      "        [    0,    38,   206,  ...,     1,     1,     1]])\n"
     ]
    }
   ],
   "source": [
    "print('[CLS] id :', transformer_tokenizer.cls_token_id)\n",
    "print('[SEP] id :', transformer_tokenizer.sep_token_id)\n",
    "print('[PAD] id :', pad_idx)\n",
    "test_one_batch = databunch.one_batch()[0]\n",
    "print('Batch shape : ',test_one_batch.shape)\n",
    "print(test_one_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Custom model\n",
    "## As mentioned [here](https://github.com/huggingface/transformers#models-always-output-tuples), every model's forward method always outputs a ``tuple`` with various elements depending on the model and the configuration parameters. In our case, we are interested to access only to the logits. \n",
    "## One way to access them is to create a custom model.\n",
    "                    \n",
    "# defining our model architecture \n",
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(self, transformer_model: PreTrainedModel):\n",
    "        super(CustomTransformerModel,self).__init__()\n",
    "        self.transformer = transformer_model\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        \n",
    "        # attention_mask\n",
    "        # Mask to avoid performing attention on padding token indices.\n",
    "        # Mask values selected in ``[0, 1]``:\n",
    "        # ``1`` for tokens that are NOT MASKED, ``0`` for MASKED tokens.\n",
    "        attention_mask = (input_ids!=pad_idx).type(input_ids.type()) \n",
    "        \n",
    "        logits = self.transformer(input_ids,\n",
    "                                  attention_mask = attention_mask)[0]   \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## set configs\n",
    "\n",
    "config = config_class.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = 5\n",
    "config.use_bfloat16 = use_fp16\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = model_class.from_pretrained(pretrained_model_name, config = config)\n",
    "custom_transformer_model = CustomTransformerModel(transformer_model = transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In pytorch-transformers, HuggingFace had implemented two specific optimizers  -  BertAdam and OpenAIAdam  -  that have been replaced by a single AdamW optimizer. \n",
    "# This optimizer matches Pytorch Adam optimizer Api, therefore, it becomes straightforward to integrate it within fastai. It is worth noting that for reproducing BertAdam specific behavior, you have to set correct_bias = False.\n",
    "\n",
    "from fastai.callbacks import *\n",
    "from transformers import AdamW\n",
    "from functools import partial\n",
    "\n",
    "CustomAdamW = partial(AdamW, correct_bias=False)\n",
    "\n",
    "learner = Learner(databunch, \n",
    "                  custom_transformer_model, \n",
    "                  opt_func = CustomAdamW, \n",
    "                  metrics=[accuracy, error_rate])\n",
    "\n",
    "# Show graph of learner stats and metrics after each epoch.\n",
    "learner.callbacks.append(ShowGraph(learner))\n",
    "\n",
    "# Put learn in FP16 precision mode. --> Seems to not working\n",
    "if use_fp16: learner = learner.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTransformerModel(\n",
      "  (transformer): RobertaForSequenceClassification(\n",
      "    (roberta): RobertaModel(\n",
      "      (embeddings): RobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (classifier): RobertaClassificationHead(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (out_proj): Linear(in_features=768, out_features=5, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(learner.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can decide to divide the model in 14 blocks :\n",
    "* 1 Embedding\n",
    "* 12 transformer\n",
    "* 1 classifier\n",
    "\n",
    "In this case, we can split our model in this way :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_layers = [learner.model.transformer.roberta.embeddings,\n",
    "              learner.model.transformer.roberta.encoder.layer[0],\n",
    "              learner.model.transformer.roberta.encoder.layer[1],\n",
    "              learner.model.transformer.roberta.encoder.layer[2],\n",
    "              learner.model.transformer.roberta.encoder.layer[3],\n",
    "              learner.model.transformer.roberta.encoder.layer[4],\n",
    "              learner.model.transformer.roberta.encoder.layer[5],\n",
    "              learner.model.transformer.roberta.encoder.layer[6],\n",
    "              learner.model.transformer.roberta.encoder.layer[7],\n",
    "              learner.model.transformer.roberta.encoder.layer[8],\n",
    "              learner.model.transformer.roberta.encoder.layer[9],\n",
    "              learner.model.transformer.roberta.encoder.layer[10],\n",
    "              learner.model.transformer.roberta.encoder.layer[11],\n",
    "              learner.model.transformer.roberta.pooler]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check groups : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner split in 14 groups\n",
      "[Sequential(\n",
      "  (0): Embedding(50265, 768, padding_idx=1)\n",
      "  (1): Embedding(514, 768, padding_idx=1)\n",
      "  (2): Embedding(1, 768)\n",
      "  (3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (4): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=5, bias=True)\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "learner.split(list_layers)\n",
    "num_groups = len(learner.layer_groups)\n",
    "print('Learner split in',num_groups,'groups')\n",
    "print(learner.layer_groups)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "Now we can finally use all the fastai build-in features to train our model. we will use **Slanted Triangular Learning Rates**, **Discriminate Learning Rate** and **gradually unfreeze the model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('untrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)\n",
    "learner.load('untrain');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we first freeze all the groups but the classifier with :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check which layer are trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTransformerModel\n",
       "======================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "======================================================================\n",
       "Embedding            [512, 768]           38,603,520 False     \n",
       "______________________________________________________________________\n",
       "Embedding            [512, 768]           394,752    False     \n",
       "______________________________________________________________________\n",
       "Embedding            [512, 768]           768        False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 512, 512]       0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 3072]          2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [512, 768]           2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [512, 768]           1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [512, 768]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [768]                590,592    True      \n",
       "______________________________________________________________________\n",
       "Tanh                 [768]                0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [768]                590,592    True      \n",
       "______________________________________________________________________\n",
       "Dropout              [768]                0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [5]                  3,845      True      \n",
       "______________________________________________________________________\n",
       "\n",
       "Total params: 125,240,069\n",
       "Total trainable params: 1,185,029\n",
       "Total non-trainable params: 124,055,040\n",
       "Optimized with 'transformers.optimization.AdamW', correct_bias=False\n",
       "Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \n",
       "Loss function : FlattenedLoss\n",
       "======================================================================\n",
       "Callbacks functions applied \n",
       "    ShowGraph"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **Slanted Triangular Learning Rates** you have to use the function ``one_cycle``. For more information please check the fastai documentation [here](https://docs.fast.ai/callbacks.one_cycle.html). \n",
    "\n",
    "To use our ``one_cycle`` we will need an optimum learning rate. We can find this learning rate by using a learning rate finder which can be called by using ``lr_find``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  error_rate  time    \n",
      "0         6.364385    #na#        01:18     \n",
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/fastai/sixel.py:16: UserWarning: You could see this plot with `libsixel`. See https://github.com/saitoha/libsixel\n",
      "  warn(\"You could see this plot with `libsixel`. See https://github.com/saitoha/libsixel\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.recorder.plot(skip_end=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will pick a value around the minimum. Here 2x10^-3 seems to be a good value.\n",
    "\n",
    "Next we will use ``fit_one_cycle`` with the chosen learning rate as the maximum learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  error_rate  time    \n",
      "0         0.654980    0.505112    0.784211  0.215789    02:01     \n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(1,max_lr=2e-3,moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('first_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)\n",
    "learner.load('first_cycle');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then unfreeze the second group of layers and repeat the operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.freeze_to(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that we use slice to create separate learning rate for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  error_rate  time    \n",
      "0         0.482140    0.408488    0.842105  0.157895    02:09     \n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(1, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('second_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)\n",
    "learner.load('second_cycle');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.freeze_to(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  error_rate  time    \n",
      "0         0.355942    0.294719    0.863158  0.136842    02:31     \n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(1, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('third_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)\n",
    "learner.load('third_cycle');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we unfreeze all the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  error_rate  time    \n",
      "0         0.345208    0.247719    0.884211  0.115789    06:36     \n",
      "1         0.183688    0.248775    0.894737  0.105263    06:33     \n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(2, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can predict examples with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category tensor(1),\n",
       " tensor(1),\n",
       " tensor([1.8102e-01, 8.1896e-01, 8.9981e-06, 1.1919e-05, 8.0093e-06]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.predict('This is the best movie of 2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category tensor(0),\n",
       " tensor(0),\n",
       " tensor([9.9691e-01, 3.0437e-03, 1.4607e-05, 1.7345e-05, 1.5531e-05]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.predict('This is the worst movie of 2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Learner\n",
    "In order to export and load the learner you can do these operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.export(file = 'transformer.pkl');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    }
   ],
   "source": [
    "path = '.'\n",
    "export_learner = load_learner(path, file = 'transformer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned [here](https://docs.fast.ai/basic_train.html#load_learner), you have to be careful that each custom classes - like ``TransformersVocab`` - are first defined before executing ``load_learner``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category tensor(0),\n",
       " tensor(0),\n",
       " tensor([9.9691e-01, 3.0437e-03, 1.4607e-05, 1.7345e-05, 1.5531e-05]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_learner.predict('This is the worst movie of 2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating prediction\n",
    "Now that the model is trained, we want to generate predictions from the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    }
   ],
   "source": [
    "def get_preds_as_nparray(ds_type) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    the get_preds method does not yield the elements in order by default\n",
    "    we borrow the code from the RNNLearner to resort the elements into their correct order\n",
    "    \"\"\"\n",
    "    preds = learner.get_preds(ds_type)[0].detach().cpu().numpy()\n",
    "    sampler = [i for i in databunch.dl(ds_type).sampler]\n",
    "    reverse_sampler = np.argsort(sampler)\n",
    "    return preds[reverse_sampler, :]\n",
    "\n",
    "test_preds = get_preds_as_nparray(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('./data/test.csv')\n",
    "sample_submission['Sentiment'] = np.argmax(test_preds,axis=1)\n",
    "sample_submission['Sentiment'] = sample_submission['Sentiment'].apply(lambda x: 'Positive' if x == 1 else 'Negative')\n",
    "\n",
    "sample_submission = sample_submission.rename(columns={'Sentiment': 'label'})\n",
    "sample_submission.drop(columns=['text'], inplace=True)\n",
    "\n",
    "sample_submission.to_csv(\"predictions1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>206</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>207</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>208</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>209</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>210</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id     label\n",
       "0      0  Positive\n",
       "1      1  Positive\n",
       "2      2  Positive\n",
       "3      3  Positive\n",
       "4      4  Negative\n",
       "..   ...       ...\n",
       "206  206  Positive\n",
       "207  207  Positive\n",
       "208  208  Positive\n",
       "209  209  Negative\n",
       "210  210  Negative\n",
       "\n",
       "[211 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('predictions1.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    119\n",
       "Negative     92\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.label.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "04af8c8ab4264a4aa24be5ce7c3d6356": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3dc1cc48d64540ce8bc345e054f718e7",
       "max": 501200538,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c04b9a4c489943fb914d74765454b956",
       "value": 501200538
      }
     },
     "06072bb801914fdbb50a818901689aaf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0db349fcc5da48ce974d5ca6a5d74ed7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0dc20e8cb6db4aaf85be250fde458fb5",
       "max": 898823,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_50aa5abe7c4a44458343a9dc2aba73dc",
       "value": 898823
      }
     },
     "0dc20e8cb6db4aaf85be250fde458fb5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0f93a2908b1d4eca979f36d4278a3598": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e1100a07ec63445f81f29fd119832e0e",
       "placeholder": "​",
       "style": "IPY_MODEL_94e96540367c40bfb560a8f692d3df96",
       "value": " 456k/456k [00:00&lt;00:00, 1.37MB/s]"
      }
     },
     "162c0469b80a41c4b09493deeb075d8e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "1e1b327155e043c68fe77d45136743f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_963c6c9ab8834d5a9c87bd4e1aebf467",
       "max": 524,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4137286f012b473ca7da96941fd7c2c8",
       "value": 524
      }
     },
     "22ed017644074184912140c8dab74662": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "25036c2d84cd4d7980c3b5e2a4a8ceb1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3dc1cc48d64540ce8bc345e054f718e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3effb5e6c7d745e0afcb18d3dfa97dbb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_04af8c8ab4264a4aa24be5ce7c3d6356",
        "IPY_MODEL_dbaec362a5f04949973a7618fd390775"
       ],
       "layout": "IPY_MODEL_b4b3cd9912ab4aad8bf6dfe20b822d37"
      }
     },
     "4137286f012b473ca7da96941fd7c2c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "50aa5abe7c4a44458343a9dc2aba73dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "58e2d230ac834afea6905419421e0c7f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6beb3d2743084253af1a8c510a43ae5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1e1b327155e043c68fe77d45136743f8",
        "IPY_MODEL_74b97ad281db4f3d925289c16fa0e937"
       ],
       "layout": "IPY_MODEL_8521940d38fa4c83aa95e1846e5e8fce"
      }
     },
     "74b97ad281db4f3d925289c16fa0e937": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_25036c2d84cd4d7980c3b5e2a4a8ceb1",
       "placeholder": "​",
       "style": "IPY_MODEL_886b261c181b4be68941c4a64d1eef55",
       "value": " 524/524 [00:00&lt;00:00, 881B/s]"
      }
     },
     "750d897db40646d09f29e1949aa87003": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7e198a334cac4ab49a5a00c81c624512": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e55f8b65bf5f4374a48b31ef690f5e73",
       "max": 456318,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_162c0469b80a41c4b09493deeb075d8e",
       "value": 456318
      }
     },
     "8521940d38fa4c83aa95e1846e5e8fce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "886b261c181b4be68941c4a64d1eef55": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8c226c92b5684e989d150a6c1fc65ee9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_06072bb801914fdbb50a818901689aaf",
       "placeholder": "​",
       "style": "IPY_MODEL_93a3957ae16b41c9b710adedaaf02156",
       "value": " 899k/899k [00:01&lt;00:00, 709kB/s]"
      }
     },
     "93a3957ae16b41c9b710adedaaf02156": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "94e96540367c40bfb560a8f692d3df96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "963c6c9ab8834d5a9c87bd4e1aebf467": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9e840112621c4243bbcd618bd0e4a550": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "af165492e3e74ed0941720ecb7ce9ffa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7e198a334cac4ab49a5a00c81c624512",
        "IPY_MODEL_0f93a2908b1d4eca979f36d4278a3598"
       ],
       "layout": "IPY_MODEL_750d897db40646d09f29e1949aa87003"
      }
     },
     "b4b3cd9912ab4aad8bf6dfe20b822d37": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c04b9a4c489943fb914d74765454b956": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "dbaec362a5f04949973a7618fd390775": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9e840112621c4243bbcd618bd0e4a550",
       "placeholder": "​",
       "style": "IPY_MODEL_22ed017644074184912140c8dab74662",
       "value": " 501M/501M [00:13&lt;00:00, 36.2MB/s]"
      }
     },
     "e1100a07ec63445f81f29fd119832e0e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e55f8b65bf5f4374a48b31ef690f5e73": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f2134963e3a44c29a237bee166bbfab9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0db349fcc5da48ce974d5ca6a5d74ed7",
        "IPY_MODEL_8c226c92b5684e989d150a6c1fc65ee9"
       ],
       "layout": "IPY_MODEL_58e2d230ac834afea6905419421e0c7f"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
